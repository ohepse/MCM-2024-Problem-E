import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit

# è®¾ç½®ç»˜å›¾é£æ ¼ï¼Œè®©å›¾è¡¨æ›´å¥½çœ‹
plt.style.use('ggplot')

# ==========================================
# ç¬¬ä¸€æ­¥ï¼šæ‹Ÿåˆç¾å®³é¢‘ç‡æ¨¡å‹ (NHPP)
# ç›®æ ‡ï¼šæ‰¾å‡º lambda(t) = a * exp(k * t) ä¸­çš„å‚æ•° a å’Œ k
# ==========================================

def fit_nhpp_model(years, counts, region_name):
    # å®šä¹‰æŒ‡æ•°å¢é•¿å‡½æ•°
    def exponential_func(t, a, k):
        return a * np.exp(k * t)

    # å°†å¹´ä»½å½’ä¸€åŒ– (ä» t=0 å¼€å§‹)ï¼Œæ–¹ä¾¿è®¡ç®—
    t_data = years - years.min()
    
    # æ‹Ÿåˆå‚æ•°
    # p0 æ˜¯åˆå§‹çŒœæµ‹å€¼ [a=1, k=0.01]
    try:
        popt, pcov = curve_fit(exponential_func, t_data, counts, p0=[1, 0.01], maxfev=5000)
        a_fit, k_fit = popt
    except:
        print(f"âš ï¸ {region_name} æ‹Ÿåˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
        a_fit, k_fit = np.mean(counts), 0.01

    return a_fit, k_fit

# è¯»å–é¢‘ç‡æ•°æ®
df_freq = pd.read_csv(r'C:\Users\mth\Desktop\20250124\code\disaster_frequency.csv')
years = df_freq['Year'].values

# åˆ†åˆ«æ‹Ÿåˆ Texas å’Œ Luzon
params = {}
for region in ['Texas_USA', 'Luzon_PHL']:
    counts = df_freq[region].values
    a, k = fit_nhpp_model(years, counts, region)
    params[region] = {'a': a, 'k': k}
    print(f"âœ… {region} æ‹Ÿåˆç»“æœ: åˆå§‹é¢‘ç‡ a={a:.2f}, æ¶åŒ–å› å­ k={k:.4f} ({(np.exp(k)-1)*100:.2f}%/å¹´)")

# ==========================================
# ç¬¬äºŒæ­¥ï¼šè®¡ç®—å•æ¬¡ç¾å®³çš„å¹³å‡æŸå¤± (Severity)
# ==========================================

df_loss = pd.read_csv(r'C:\Users\mth\Desktop\20250124\code\loss_severity.csv')

# è®¡ç®—æ¯ä¸ªåœ°åŒºçš„å¹³å‡å•æ¬¡æŸå¤± (Expected Loss per Event)
avg_severity = df_loss.groupby('Region')['Total_Loss_000_USD'].mean()

# å¦‚æœæŸä¸ªåœ°åŒºæ²¡æœ‰æŸå¤±æ•°æ®ï¼ˆæç«¯æƒ…å†µï¼‰ï¼Œç»™ä¸€ä¸ªé»˜è®¤å€¼
for region in ['Texas_USA', 'Luzon_PHL']:
    if region not in avg_severity:
        avg_severity[region] = 100000 # é»˜è®¤ 1äº¿ç¾å…ƒ
    print(f"ğŸ’° {region} å¹³å‡å•æ¬¡æŸå¤±: ${avg_severity[region]/1000:.2f} Million")

# ==========================================
# ä¼˜åŒ–åçš„ç¬¬ä¸‰æ­¥ï¼šå†³ç­–æ¨¡å‹ (å¼•å…¥ä¿®æ­£å› å­)
# ==========================================

df_econ = pd.read_csv(r'C:\Users\mth\Desktop\20250124\code\economic_data.csv')
future_years = np.arange(1990, 2060) # é¢„æµ‹åˆ° 2060 å¹´
t_future = future_years - 1990

# è®¾å®šæ¨¡å‹å‡è®¾å‚æ•°
PROFIT_MARGIN = 0.20      # ä¿é™©å…¬å¸åˆ©æ¶¦ç‡ + è¿è¥æˆæœ¬ (20%)
AFFORDABILITY_RATIO = 0.05 # å®¶åº­èƒ½æ‹¿å‡ºæ”¶å…¥çš„ 5% ä¹°ä¿é™©


# 1. è®¡ç®—æŸå¤±åŸºå‡† (L0) - ä½¿ç”¨ä¸­ä½æ•°è€Œéå¹³å‡å€¼ï¼Œæ’é™¤æç«¯å€¼å¹²æ‰°
# ---------------------------------------------------------
# è®¡ç®—ä¸­ä½æ•°
median_severity = df_loss.groupby('Region')['Total_Loss_000_USD'].median()
# ä¸ºäº†é˜²æ­¢ä¸­ä½æ•°è¿‡å°ï¼ˆæ¯”å¦‚æœ‰å¾ˆå¤šå°ç¾å®³ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å– Mean å’Œ Median çš„åŠ æƒå¹³å‡
# æˆ–è€…ç›´æ¥ç”¨ log-normal åˆ†å¸ƒçš„æœŸæœ›å€¼ï¼ˆæ›´é«˜çº§ï¼Œä½†å¤§ä¸€å¯ä»¥ç”¨ç®€å•åŠ æƒï¼‰
mean_severity = df_loss.groupby('Region')['Total_Loss_000_USD'].mean()

L0_dict = {}
for region in ['Texas_USA', 'Luzon_PHL']:
    # ç»¼åˆè€ƒé‡ï¼š70%æƒé‡ç»™ä¸­ä½æ•°ï¼Œ30%ç»™å¹³å‡å€¼
    if region in median_severity:
        raw_L0 = 0.7 * median_severity[region] + 0.3 * mean_severity[region]
    else:
        raw_L0 = 100000 # é»˜è®¤å€¼
    L0_dict[region] = raw_L0

# 2. è®¾å®šæ¨¡å‹å‚æ•° (Model Parameters)
# ---------------------------------------------------------
params_setting = {
    'Texas_USA': {
        'coverage_ratio': 0.50,  # å‘è¾¾å›½å®¶ï¼šçº¦50%æŸå¤±ç”±ä¿é™©è¦†ç›–
        'profit_margin': 0.15,   # åˆ©æ¶¦ç‡
        'burden_start': 0.6     # å½“å‰ä¿è´¹å æ”¯ä»˜èƒ½åŠ›çš„ 35% (å¸‚åœºå¥åº·)
    },
    'Luzon_PHL': {
        'coverage_ratio': 0.10,  # å‘å±•ä¸­å›½å®¶ï¼šä»…10%æœ‰ä¿é™© (Protection Gap å·¨å¤§)
        'profit_margin': 0.20,   # é£é™©æ›´é«˜ï¼Œè¦æ±‚åˆ©æ¶¦æ›´é«˜
        'burden_start': 0.45     # æ”¶å…¥ä½ï¼Œå½“å‰ä¿é™©æ¸—é€ç‡æä½
    }
}

future_years = np.arange(1990, 2060)
t_future = future_years - 1990
current_idx = 2024 - 1990

results = {}

for region in ['Texas_USA', 'Luzon_PHL']:
    # è¯»å– NHPP å‚æ•°
    a = params[region]['a']
    k = params[region]['k']
    
    # è¯»å–ä¿®æ­£åçš„åŸºå‡†æŸå¤±
    raw_L0 = L0_dict[region]
    
    # è¯»å–ç‰¹å®šåœ°åŒºçš„è®¾å®š
    settings = params_setting[region]
    insurance_L0 = raw_L0 * settings['coverage_ratio'] # åªè®¡ç®—ä¿é™©èµ”ä»˜çš„éƒ¨åˆ†
    
    # è¯»å–ç»æµå¢é•¿ç‡
    last_econ = df_econ.iloc[-1]
    if 'Texas' in region:
        g_inc = last_econ['Texas_Growth']
    else:
        g_inc = last_econ['Luzon_Growth']
    
    # --- è®¡ç®— P_min (ä¿é™©å…¬å¸æˆæœ¬) ---
    # å…¬å¼ï¼šRate * Freq * Insured_Severity
    lambda_t = a * np.exp(k * t_future)
    
    # å‡è®¾èµ„äº§ä»·å€¼éšæ”¶å…¥å¢é•¿ (g_inc) åŠ ä¸Š 1% çš„æ²¿æµ·èµ„äº§æº¢ä»·
    g_asset = g_inc + 0.01 
    expected_loss_t = insurance_L0 * ((1 + g_asset) ** t_future)
    
    p_min_curve = (1 + settings['profit_margin']) * lambda_t * expected_loss_t
    
    # --- è®¡ç®— P_max (æ”¯ä»˜èƒ½åŠ›ä¸Šé™) ---
    # æ ¸å¿ƒé€»è¾‘ï¼šæˆ‘ä»¬ä¸éœ€è¦çŸ¥é“å…·ä½“çš„ç¾å…ƒé‡‘é¢ï¼Œåªéœ€è¦çŸ¥é“ç›¸å¯¹è¶‹åŠ¿
    # è®¾å®š 2024 å¹´çš„ P_max æ˜¯å½“å‰ P_min çš„ X å€
    
    current_cost = p_min_curve[current_idx]
    # å¦‚æœ burden_start = 0.35ï¼Œè¯´æ˜ P_max = Cost / 0.35
    current_limit = current_cost / settings['burden_start']
    
    # ä¸Šé™éšæ”¶å…¥å¢é•¿
    p_max_curve = current_limit * ((1 + g_inc) ** (t_future - current_idx))

    # --- å¯»æ‰¾äº¤ç‚¹ ---
    diff = p_min_curve - p_max_curve
    # åªçœ‹ 2025 ä»¥åçš„äº¤ç‚¹
    future_break_even = np.where((diff > 0) & (future_years > 2025))[0]
    
    if len(future_break_even) > 0:
        crash_year = future_years[future_break_even[0]]
    else:
        crash_year = None
        
    results[region] = {
        'years': future_years,
        'p_min': p_min_curve,
        'p_max': p_max_curve,
        'crash_year': crash_year,
        'k': k
    }

# æ‰“å°æ–°ç»“æœ
print("-" * 50)
for region, res in results.items():
    print(f"ğŸŒ åœ°åŒº: {region}")
    print(f"   ğŸ“Š ä¿é™©è¦†ç›–ç‡è®¾å®š: {params_setting[region]['coverage_ratio']*100}%")
    if res['crash_year']:
        print(f"   âš ï¸ é¢„è®¡å¸‚åœºå´©æºƒå¹´ä»½: {res['crash_year']} å¹´")
    else:
        print(f"   âœ… 2060å¹´å‰ä¿æŒå¯æŒç»­")
print("-" * 50)

# ==========================================
# ç¬¬å››æ­¥ï¼šå¯è§†åŒ–ç»“æœ
# ==========================================

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

for ax, region in zip(axes, ['Texas_USA', 'Luzon_PHL']):
    res = results[region]
    
    # ç»˜åˆ¶æ›²çº¿
    ax.plot(res['years'], res['p_min'], 'r-', label='Insurance Cost (Risk)', linewidth=2)
    ax.plot(res['years'], res['p_max'], 'b--', label='Affordability Limit', linewidth=2)
    
    # æ ‡è®°å½“å‰å¹´ä»½
    ax.axvline(x=2024, color='gray', linestyle=':', alpha=0.5)
    
    # æ ‡è®°å´©æºƒå¹´ä»½
    if res['crash_year']:
        ax.plot(res['crash_year'], res['p_min'][res['years'] == res['crash_year']], 'ko', markersize=10)
        ax.annotate(f'Market Failure\n{res["crash_year"]}', 
                    xy=(res['crash_year'], res['p_min'][res['years'] == res['crash_year']]),
                    xytext=(-60, 40), textcoords='offset points',
                    arrowprops=dict(facecolor='black', shrink=0.05))
        ax.axvspan(res['crash_year'], 2060, color='red', alpha=0.1, label='Uninsurable Zone')
    
    ax.set_title(f"{region} Insurance Sustainability")
    ax.set_xlabel("Year")
    ax.set_ylabel("Financial Scale (Normalized)")
    ax.legend()
    ax.set_xlim(2000, 2060)

plt.tight_layout()
plt.show()

print("\nåˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹å¼¹å‡ºçš„å›¾è¡¨ã€‚")
for region, res in results.items():
    if res['crash_year']:
        print(f"âš ï¸ è­¦å‘Š: {region} é¢„è®¡å°†åœ¨ {res['crash_year']} å¹´è¾¾åˆ°ä¸å¯ä¿ä¸´ç•Œç‚¹ã€‚")
    else:
        print(f"âœ… {region} åœ¨ 2060 å¹´å‰ä¿æŒå¯æŒç»­ã€‚")